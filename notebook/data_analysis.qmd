---
title: "Green Nest Material Meta-Analysis"
subtitle: "The adaptive value of green nest material across birds: A systematic review and meta-analysis"
author: "Shreya Dimri"
date: last-modified

format:
  html:
   toc: true 
   toc-title: "Table of Contents" 
   toc-depth: 2 
   toc-expand: 3 
   toc-location: left 
   mainfont: Verdana 
   monofont: Jetbrains Mono 
   fontsize: 12pt 
   code-fold: show
   df-print: paged 
   highlight-style: github 
   pdf: default
editor: visual
---

```{r setup, warning=FALSE, message=FALSE, echo=F}

# Setting up workspace

# For plotting trees, and although not strictly necessary, we may need the `ggtree` R package, which you should be able to install by running:
# if (!require("BiocManager", quietly = TRUE))
# install.packages("BiocManager")
# BiocManager::install("ggtree")

#devtools::install_github("daniel1noble/orchaRd", ref = "main", force = TRUE)
pacman::p_load(here, tidyverse, metafor,ggpubr,orchaRd,ggpubfigs) #Packages needed
rm(list=ls()) ## cleaning up
set.seed(430) #set seed for reproducibility (for random number generation)
# Loading cleaned dataset
dataset_analysis<- read_csv(here::here("data/03_data_cleaning/dataset_analysis.csv"))

# Functions needed

# function to estimate typical sampling error variance obtained from 
# https://github.com/Yefeng0920/heterogeneity_ecoevo/tree/main/function
sigma2_v <- function(mod){
  sigma2_v <- sum(1 / mod$vi) * (mod$k - 1) /
    (sum(1 / mod$vi)^2 - sum((1 / mod$vi)^2))
  return(sigma2_v)
}
```

### Creating Phylogeny for the plot

```{r}
# install.packages("pacman")
# load packages
pacman::p_load(rotl,
               ape,
               ggtree)
# Doesn't matter if I take dataset_lnRR or dataset_SMDH
bird_species <- unique(dataset_analysis$bird_species)

# extracting taxonomic information
taxa <- rotl::tnrs_match_names(names = bird_species)
taxa
# check approximate matches
taxa[taxa$approximate_match==TRUE & !(is.na(taxa$approximate_match)),]
# phylogenetic information for our species from the Open Tree of Life
tree <- rotl::tol_induced_subtree(ott_ids = taxa[["ott_id"]], label_format = "name")
ape::is.binary(tree)
# here are the species included in the tree
sort(tree$tip.label)

# removing the underscore "_" from the tree tip.label
tree$tip.label <- gsub("_"," ", tree$tip.label)
sort(tree$tip.label)

# compute branch lengths of tree
phylo_branch <- compute.brlen(tree, method = "Grafen", power = 1)

# check tree is ultrametric
is.ultrametric(phylo_branch) # TRUE

# matrix to be included in the models
bird_phylo <- vcv(phylo_branch, cor = T)
bird_phylo

plot(tree) #check: https://www.rdocumentation.org/packages/ape/versions/5.3/topics/plot.phylo
```

### Visualizing random effects structure

```{r}
# install.packages("devtools")
#devtools::install_github("davidsjoberg/ggsankey")
library(ggsankey)

sankey_data <- dataset_analysis %>%
  select(Observation_ID, repeated_trait_ID_coded, paper_ID, experiment_ID_coded, group_ID_coded)%>%
  mutate(across(c(Observation_ID, repeated_trait_ID_coded, paper_ID, experiment_ID_coded, group_ID_coded), as.character)) %>%
  make_long(Observation_ID, repeated_trait_ID_coded, paper_ID, experiment_ID_coded, group_ID_coded)

sankey_data <- dataset_analysis %>%
  select(paper_ID, bird_species, population_ID)%>%
  mutate(across(c(paper_ID, bird_species, population_ID), as.character)) %>%
  make_long(paper_ID, bird_species, population_ID)


ggplot(sankey_data, aes(x = x, 
               next_x = next_x, 
               node = node, 
               next_node = next_node,
               fill = factor(node))) +
  geom_sankey() +
  scale_fill_discrete(drop=FALSE) +
  theme(legend.position = "none")

ggplot(sankey_data, aes(x = x, next_x = next_x, node = node, next_node = next_node, fill = factor(node))) +
  geom_alluvial(flow.alpha = .6) +
  scale_fill_viridis_d(drop = FALSE) +
  theme_alluvial(base_size = 18) +
  labs(x = NULL) +
  theme(legend.position = "none",
        plot.title = element_text(hjust = .5))


```

# Preparing datasets

```{r seperating datasets for analysis}

## For lnRR
# selecting dataset which are not flagged
dataset_lnRR<-dataset_analysis%>%
   filter(lnRR_sign != "NA" | lnRR_variance != "NA")%>%
  filter(proxy_decision == "include")

# selecting dataset which are flagged
lnRR_con_flagged<-dataset_analysis%>%
   filter(lnRR_sign != "NA" | lnRR_variance != "NA")%>%
  filter(proxy_decision != "SMDH only" | proxy_decision != "contingency table" )

# selecting dataset without those using 0 as ES because authors reported no effect
lnRR_sin_missingES <- dataset_lnRR %>% 
   filter(!proxy_comment %in% c("use 0 as ES"))

lnRR_flagged_no_missingES<- lnRR_con_flagged %>% 
   filter(!proxy_comment %in% c("use 0 as ES"))

## For SMDH
# selecting dataset which are not flagged
dataset_SMDH<-dataset_analysis%>%
   filter(proxy_decision == "include"| proxy_decision == "SMDH only"|proxy_decision =="contingency table") %>% filter(SMDH_sign != "NA")


# selecting dataset which are flagged
SMDH_con_flagged<-dataset_analysis%>%
   filter(SMDH_sign != "NA")

# selecting dataset without those using 0 as ES because authors reported no effect

SMDH_sin_missingES <- dataset_SMDH %>% 
   filter(!proxy_comment %in% c("use 0 as ES"))

SMDH_flagged_no_missingES<- SMDH_con_flagged %>% 
   filter(!proxy_comment %in% c("use 0 as ES"))

# selecting dataset which are not flagged but without the SMDH calculated from inferential statistics 

SMDH_no_inferential<-dataset_analysis%>%
  filter(proxy_decision == "include")%>% filter(SMDH_sign != "NA")
```

# Overall effect : Intercept-only meta-analytic model

*"Does adding green material to the nest have an adaptive function across the bird species that perform this behaviour?"*

## using lnRR

```{r intercept-only-model-lnRR}
VCV_lnRR<- vcalc(vi = lnRR_variance,
                  cluster = paper_ID,
                  obs = Observation_ID,
                  data = dataset_lnRR,
                  rho = 0.5 # assuming that the effect sizes within the same study are correlated with rho = 0.5
                  )

intercept_lnRR<- rma.mv(yi = lnRR_sign, # specify lnRR as the effect size measure;
                    V = VCV_lnRR, # specify lnRR's sampling variance-covariance matrix;
                    mods = ~ 1,
                    random = list(~ 1 | paper_ID,
                                  ~ 1 | Observation_ID,
                                  ~ 1 | group_ID_coded,
                                  ~ 1 | population_ID,
                                  ~ 1 | bird_species),
                    method = "REML",
                    control = list(optimizer="optim"),
                    test = "t",
                    data = dataset_lnRR)
# saving the model
saveRDS(intercept_lnRR, file = here::here("model/intercept_lnRR.rds"))


```

Exploring heterogeneity in intercept only model

This is the function from Yefeng's Github for interpretting heterogeneity. I have to download the data used for this function to be able to use it. For now I am using the values from the table directly so I should just delete it later before finishing the code.

```{r function-interpret-heterogeneity}
# ## Function is from the Pluralistic approach to heterogeneity from Yefeng's Pre-print repository from GitHub
# 
# #-----------------------heterogeneity interpretation-----------------------#
# het_interpret <- function(observed_value, het_type, es_type, data) {
#   
#   if (!het_type %in% c("I2", "CVH", "M", "sigma2", "V_bar")) {
#     stop("Invalid heterogeneity type. Choose from 'I2', 'CVH', 'M', 'sigma2', or 'V_bar'.")
#   }
#   
#   if (!es_type %in% unique(data$es.type)) {
#     stop("Invalid effect size type. Check the levels of 'es.type'.")
#   }
#   
#   filtered_data <- data %>% filter(es.type == es_type)
#   
#   if (nrow(filtered_data) == 0) {
#     stop("No data available for the selected effect size type.")
#   }
#   
#   het_values <- filtered_data[[het_type]]
#   
#   percentiles <- quantile(het_values, probs = seq(0, 1, by = 0.05), na.rm = TRUE)
#   
#   lower_bound <- max(percentiles[percentiles <= observed_value], na.rm = TRUE)
#   upper_bound <- min(percentiles[percentiles >= observed_value], na.rm = TRUE)
#   lower_percentile <- names(percentiles)[percentiles == lower_bound]
#   upper_percentile <- names(percentiles)[percentiles == upper_bound]
#   
#   percentile_range <- paste0(lower_percentile, "-", upper_percentile, "th percentile")
#   
#   # return the results
#   return(tibble::tibble(
#     observed_value = observed_value,
#     het_type = het_type,
#     es_type = es_type,
#     percentile_range = percentile_range
#   ))
# }
# x<-het_interpret(observed_value= I2_main_model_vector[1], 
#                  het_type = "I2", 
#                  es_type = "lnRR_sign", 
#                  data= intercept_lnRR)

```

## lnRR-heterogeneity

Let us look at the heterogeneity in lnRR intercept-only model

```{r}


# Then also:
# # Typical sampling variance (which captures the statistical noise of the data, 
# # but is rarely reported in the current meta-analytic practice):
sigma2_v(intercept_lnRR)

# To calculate heterogeneity, these are the functions from orchaRd:
# # I2, CV and M
sigma2_main_model_vector <- sum(intercept_lnRR$sigma2)
# 0.11, 0.27, and 0.57 for lnRR
I2_main_model_vector <- orchaRd::i2_ml(intercept_lnRR)
# 0.88, 0.95, and 0.99 for lnRR
CV_main_model_vector <- orchaRd::cvh1_ml(intercept_lnRR)
# CVH2 (CVH1) - 1.36 (1.16), 3.76 (1.94), and 12.1 (3.48) for lnRR
M_main_model_vector <- orchaRd::m1_ml(intercept_lnRR)
# M2(M1) - 0.58 (0.54), 0.79 (0.66), and 0.78 for lnRR;

# # # Total unstandardized raw variance (i.e. total heterogeneity)
round(sum(intercept_lnRR$sigma2), 3)

```

## using SMDH

We are only running these analysis for the fitness proxy labelled "included". Some proxies have been flagged and we will run them in a sensitivity analysis only

their sampling variances will be fitted as variance--covariance matrices assuming a 0.5 correlation (ρs) between sampling variances from the same paper_ID (Noble et al. 2017).

The MLMA using SMDH as the effect size measure incorporate the imputed sampling variance

```{r intercept-only-model-SMDH}

VCV_SMDH <- vcalc(vi = SMDH_variance,
                  cluster = paper_ID,
                  obs = Observation_ID,
                  data = dataset_SMDH,
                  rho = 0.5 # assuming that the effect sizes within the same study are correlated with rho = 0.5
                  )

intercept_SMDH<- rma.mv(yi = SMDH_sign, # specify SMDH as the effect size measure;
                    V = VCV_SMDH, # specify SMDH's sampling variance-covariance matrix;
                    mods = ~ 1,
                    random = list(~ 1 | paper_ID,
                                  ~ 1 | Observation_ID,
                                  ~ 1 | group_ID_coded,
                                  ~ 1 | population_ID,
                                  ~ 1 | bird_species),
                    method = "REML",
                    control = list(optimizer="optim"),
                    test = "t",
                    data = dataset_SMDH)

# saving the model
# saveRDS(intercept_SMDH, file = here::here("model/intercept_SMDH.rds"))
```

## SMDH-heterogeneity

Now looking at the intercept only model

```{r}
summary(intercept_SMDH)
predict(intercept_SMDH)

# Then also:
# # Typical sampling variance (which captures the statistical noise of the data, 
# # but is rarely reported in the current meta-analytic practice):
sigma2_v(intercept_SMDH)

# To calculate heterogeneity, these are the functions from orchaRd:
# # I2, CV and M
sigma2_main_model_vector <- sum(intercept_SMDH$sigma2)
# 0.54, 1.25, and 3.03 for SMD;
I2_main_model_vector <- orchaRd::i2_ml(intercept_SMDH)
# 0.78, 0.89, and 0.96 for SMD
# 0.88, 0.95, and 0.99 for lnRR
CV_main_model_vector <- orchaRd::cvh1_ml(intercept_SMDH)
# CVH2 (CVH1) - 1.36 (1.16), 3.76 (1.94), and 12.1 (3.48) for lnRR
M_main_model_vector <- orchaRd::m1_ml(intercept_SMDH)
# M2 (M1) - 0.58 (0.54), 0.79 (0.66), and 0.78 for lnRR

# # # Total unstandardized raw variance (i.e. total heterogeneity)
round(sum(intercept_SMDH$sigma2), 3)

```

## Bivariate Meta-analytical model

For the overall effect size (i.e., the meta-analytical mean), we will run the bivariate multilevel meta-analytic model suggested by Yang et al. (2024), which models both lnRR and SMD(H) simultaneously (i.e., including them both as response variables and estimating their correlation; random).

```{r}
dataset_bivariate <- data.frame(paper_ID = c(dataset_lnRR$paper_ID, dataset_SMDH$paper_ID),
                      Observation_ID = c(dataset_lnRR$Observation_ID, dataset_SMDH$Observation_ID),
                      group_ID_coded = c(dataset_lnRR$group_ID_coded, dataset_SMDH$group_ID_coded),
                      population_ID = c(dataset_lnRR$population_ID, dataset_SMDH$population_ID),
                      bird_species = c(dataset_lnRR$bird_species, dataset_SMDH$bird_species),
                      ES = c(dataset_lnRR$lnRR_sign, dataset_SMDH$SMDH_sign),
                      V_ES = c(dataset_lnRR$lnRR_variance, dataset_SMDH$SMDH_variance),
                      ES_measure = c(rep("lnRR", nrow(dataset_lnRR)), rep("SMDH", nrow(dataset_SMDH)))
                      )

VCV_bivariate <- vcalc(vi = V_ES, # sampling variances of lnRR and SMD that are correlated within the same study;
             cluster = paper_ID, # study identity;
             type = ES_measure, # different types of effect size measures underlying the observed effect sizes;
             data = dataset_bivariate, # the long format data frame;
             rho = 0.2, # assuming that the effect sizes within the same study are correlated with rho = 0.5.
             nearpd = TRUE # specify whether impose the non positive definite VCV matrix (not invertible) to the nearest positive semi-definite matrix 
             )

Bivariate_model <- rma.mv(yi = ES, # specify the effect size estimate (the variable ES in our case);
                V = VCV_bivariate, # specify the imputed variance-covariance matrix;
                mods = ~ ES_measure - 1, # specify the variable "ES_measure" indicating the types of effect size measures;
                random = list(~ ES_measure | paper_ID, 
                              ~ ES_measure | Observation_ID,
                              ~ 1 | group_ID_coded,
                              ~ 1 | population_ID,
                              ~ 1 | bird_species
                              ), # add correlated random effects corresponding to the lnRR and SMD parameters in the same study;
                struct = "UN", # impose an unstructured variance-covariance of the study-specific random effects;
                test = "t", # t distribution is specified to test the overall effect against the null hypothesis and construct confidence intervals;
                method = "REML", # restricted likelihood maximum is assigned as the estimator for variance components as suggested;
                data = dataset_bivariate, # the long format dataset
                sparse = T
               )

saveRDS(Bivariate_model, file = here::here("sensitivity_analysis/bivariate_model.rds"))

summary(Bivariate_model)
```

```{r WARNING = F}
pacman::p_load(ellipse)
ab.l <- matreg(y=2, x=1, R=Bivariate_model$G, cov=TRUE, means=coef(Bivariate_model), n=Bivariate_model$g.levels.comb.k) # fit regression model

xy <- ellipse(Bivariate_model$G, centre=coef(Bivariate_model), level=0.95) # get 95% coverage region
ellipse_df <- data.frame(x = xy[, 1], y = xy[, 2]) # convert it int dataframe so that we can use ggplot to make a figure

pivot_wider(dataset_bivariate, names_from = ES_measure, values_from = c(ES, V_ES)) %>%
  ggplot() + 
  geom_point(aes(x = ES_lnRR, y = ES_SMDH, size = 1/sqrt(V_ES_lnRR)), color = "#1B9E77", alpha = 0.5) + 
  geom_point(aes(x = coef(Bivariate_model)[1], y = coef(Bivariate_model)[2]), color = "red", size = 2) + 
  geom_abline(intercept = ab.l$tab$beta[1], slope = ab.l$tab$beta[2]) +
  geom_path(data = ellipse_df, aes(x = x, y = y), color = "gray50") +
  #scale_x_continuous(limits = c(-2.5, 2.5)) + 
  #scale_y_continuous(limits = c(-2.5, 2.5)) + 
  guides(size = "none") + 
  labs(x = "lnRR", y = "SMD") + 
  theme_bw()
```

There is a very high negative correlation between the two effect sizes. This probably is an artifact of the data and not a true correlation. If you look at the model summary, the $tau^2$ for lnRR, it is extremely small 0.0008, i.e., there is very little variance. This could also be stemming from the fact that the log values in the dataset could be causing this. For SMDH on the other hand, the $tau^2$ is 0.1681 that is much larger. This difference in the variance estimate itself could be causing this artifact of the model. I will only go ahead to present this model as a senstivity analysis because I am not completely convinced by it's robustness.

# Sensitivity Analysis

### Sensitivity Analysis with flagged proxies

```{r}

# Preparing new variance-covariance matrix

VCV_lnRR_flagged <- vcalc(vi = lnRR_variance,
                  cluster = paper_ID,
                  obs = Observation_ID,
                  data = lnRR_con_flagged,
                  rho = 0.5 # assuming that the effect sizes within the same study are correlated with rho = 0.5
                  )


## Running intercept only model

SA_lnRR_flagged<- rma.mv(yi = lnRR_sign, # specify lnRR as the effect size measure;
                    V = VCV_lnRR_flagged, # specify lnRR's sampling variance-covariance matrix;
                    mods = ~ 1,
                    random = list(~ 1 | paper_ID,
                                  ~ 1 | Observation_ID,
                                  ~ 1 | group_ID_coded,
                                  ~ 1 | population_ID,
                                  ~ 1 | bird_species),
                    method = "REML",
                    control = list(optimizer="optim"),
                    test = "t",
                    data = lnRR_con_flagged)


# saving the model
saveRDS(SA_lnRR_flagged, file = here::here("sensitivity_analysis/SA_lnRR_flagged.rds"))

# What is the effect now?

summary(SA_lnRR_flagged)
predict(SA_lnRR_flagged)

## Now for SMDH 

# Preparing new variance-covariance matrix

VCV_SMDH_flagged <- vcalc(vi = SMDH_variance,
                  cluster = paper_ID,
                  obs = Observation_ID,
                  data = SMDH_con_flagged,
                  rho = 0.5 # assuming that the effect sizes within the same study are correlated with rho = 0.5
                  )


## Running intercept only model

SA_SMDH_flagged<- rma.mv(yi = SMDH_sign, # specify lnRR as the effect size measure;
                    V = VCV_SMDH_flagged, # specify lnRR's sampling variance-covariance matrix;
                    mods = ~ 1,
                    random = list(~ 1 | paper_ID,
                                  ~ 1 | Observation_ID,
                                  ~ 1 | group_ID_coded,
                                  ~ 1 | population_ID,
                                  ~ 1 | bird_species),
                    method = "REML",
                    control = list(optimizer="optim"),
                    test = "t",
                    data = SMDH_con_flagged)

# saving the model
saveRDS(SA_SMDH_flagged, file = here::here("sensitivity_analysis/SA_SMDH_flagged.rds"))

# What is the effect now?

summary(SA_SMDH_flagged)
predict(SA_SMDH_flagged)

```

### Sensitivity Analysis without 0 ES

```{r}

# Preparing new variance-covariance matrix

VCV_lnRR_no_missingES <- vcalc(vi = lnRR_variance,
                  cluster = paper_ID,
                  obs = Observation_ID,
                  data = lnRR_sin_missingES,
                  rho = 0.5 # assuming that the effect sizes within the same study are correlated with rho = 0.5
                  )


## Running intercept only model

SA_lnRR_no_missingES<- rma.mv(yi = lnRR_sign, # specify lnRR as the effect size measure;
                    V = VCV_lnRR_no_missingES, # specify lnRR's sampling variance-covariance matrix;
                    mods = ~ 1,
                    random = list(~ 1 | paper_ID,
                                  ~ 1 | Observation_ID,
                                  ~ 1 | group_ID_coded,
                                  ~ 1 | population_ID,
                                  ~ 1 | bird_species),
                    method = "REML",
                    control = list(optimizer="optim"),
                    test = "t",
                    data = lnRR_sin_missingES)


# saving the model
saveRDS(SA_lnRR_no_missingES, file = here::here("sensitivity_analysis/SA_lnRR_no_missingES.rds"))

# What is the effect now?

summary(SA_lnRR_no_missingES)
predict(SA_lnRR_no_missingES)



## Now we do this for SMDH

# Preparing new variance-covariance matrix

VCV_SMDH_no_missingES <- vcalc(vi = SMDH_variance,
                  cluster = paper_ID,
                  obs = Observation_ID,
                  data = SMDH_sin_missingES,
                  rho = 0.5 # assuming that the effect sizes within the same study are correlated with rho = 0.5
                  )


## Running intercept only model

SA_SMDH_no_missingES<- rma.mv(yi = SMDH_sign, # specify lnRR as the effect size measure;
                    V = VCV_SMDH_no_missingES, # specify lnRR's sampling variance-covariance matrix;
                    mods = ~ 1,
                    random = list(~ 1 | paper_ID,
                                  ~ 1 | Observation_ID,
                                  ~ 1 | group_ID_coded,
                                  ~ 1 | population_ID,
                                  ~ 1 | bird_species),
                    method = "REML",
                    control = list(optimizer="optim"),
                    test = "t",
                    data = SMDH_sin_missingES)

# saving the model
saveRDS(SA_SMDH_no_missingES, file = here::here("sensitivity_analysis/SA_SMDH_no_missingES.rds"))

# What is the effect now?

summary(SA_SMDH_no_missingES)
predict(SA_SMDH_no_missingES)

```

### Sensitivity Analysis with flagged proxies and no missing ES

```{r}

# Preparing new variance-covariance matrix

VCV_flagged_no_missingES <- vcalc(vi = lnRR_variance,
                  cluster = paper_ID,
                  obs = Observation_ID,
                  data = lnRR_flagged_no_missingES,
                  rho = 0.5 # assuming that the effect sizes within the same study are correlated with rho = 0.5
                  )


## Running intercept only model

SA_lnRR_flagged_no_missingES<- rma.mv(yi = lnRR_sign, # specify lnRR as the effect size measure;
                    V = VCV_flagged_no_missingES, # specify lnRR's sampling variance-covariance matrix;
                    mods = ~ 1,
                    random = list(~ 1 | paper_ID,
                                  ~ 1 | Observation_ID,
                                  ~ 1 | group_ID_coded,
                                  ~ 1 | population_ID,
                                  ~ 1 | bird_species),
                    method = "REML",
                    control = list(optimizer="optim"),
                    test = "t",
                    data = lnRR_flagged_no_missingES)


# saving the model
saveRDS(SA_lnRR_flagged_no_missingES, file = here::here("sensitivity_analysis/SA_lnRR_flagged_no_missingES.rds"))

# What is the effect now?

summary(SA_lnRR_flagged_no_missingES)
predict(SA_lnRR_flagged_no_missingES)


## with SMDH

# Preparing new variance-covariance matrix

VCV_SMDH_flagged_no_missingES <- vcalc(vi = SMDH_variance,
                  cluster = paper_ID,
                  obs = Observation_ID,
                  data = SMDH_flagged_no_missingES,
                  rho = 0.5 # assuming that the effect sizes within the same study are correlated with rho = 0.5
                  )


## Running intercept only model

SA_SMDH_flagged_no_missingES<- rma.mv(yi = SMDH_sign, # specify lnRR as the effect size measure;
                    V = VCV_SMDH_flagged_no_missingES, # specify lnRR's sampling variance-covariance matrix;
                    mods = ~ 1,
                    random = list(~ 1 | paper_ID,
                                  ~ 1 | Observation_ID,
                                  ~ 1 | group_ID_coded,
                                  ~ 1 | population_ID,
                                  ~ 1 | bird_species),
                    method = "REML",
                    control = list(optimizer="optim"),
                    test = "t",
                    data = SMDH_flagged_no_missingES)


# saving the model
saveRDS(SA_SMDH_flagged_no_missingES, file = here::here("sensitivity_analysis/SA_SMDH_flagged_no_missingES.rds"))


# What is the effect now?

summary(SA_SMDH_flagged_no_missingES)
predict(SA_SMDH_flagged_no_missingES)
```

### Sensitivity analysis only using effect sizes calculated from means, SDs, and ns

(i.e., excluding any effect sizes calculated from inferential statistics)

```{r}
# Preparing new variance-covariance matrix

VCV_SMDH_no_inferential <- vcalc(vi = SMDH_variance,
                  cluster = paper_ID,
                  obs = Observation_ID,
                  data = SMDH_no_inferential,
                  rho = 0.5 # assuming that the effect sizes within the same study are correlated with rho = 0.5
                  )


## Running intercept only model

SA_SMDH_no_inferential<- rma.mv(yi = SMDH_sign, # specify lnRR as the effect size measure;
                    V = VCV_SMDH_no_inferential, # specify lnRR's sampling variance-covariance matrix;
                    mods = ~ 1,
                    random = list(~ 1 | paper_ID,
                                  ~ 1 | Observation_ID,
                                  ~ 1 | group_ID_coded,
                                  ~ 1 | population_ID,
                                  ~ 1 | bird_species),
                    method = "REML",
                    control = list(optimizer="optim"),
                    test = "t",
                    data = SMDH_no_inferential)


# saving the model
saveRDS(SA_SMDH_no_inferential, file = here::here("sensitivity_analysis/SA_SMDH_no_inferential.rds"))


# What is the effect now?

summary(SA_SMDH_no_inferential)
predict(SA_SMDH_no_inferential)
```

### Different values of sampling variance correlation

[**Robust variance estimation to guard against arbitary value of sampling correlation**]{.underline} - 'robust()' function from R package 'metafor' (Viechtbauer 2010) using 'CR2' (bias reduced linearization correction) from the R package 'clubSandwich' (Pustejovsky 2024) for small-sample size adjustment.

At the moment, this is not working..

```{r}
#MLMA_lnRR_RVE<- robust(MLMA_lnRR_VCV,
#                        cluster = paper_ID,
#                        clubSandwich = TRUE,
#                        verbose=T)

# # summary(MLMA_lnRR_RVE)
# I2_CI <- i2_ml(MLMA_lnRR_RVE) # Relative heterogeneity
# round(I2_CI,2) # absolute heterogeneity is reported in the summary of the model
```

::: callout-important
Sensitivity Analysis

We will also perform a sensitivity analysis using 0.3 and 0.7 correlation between the sampling variances from the same paper_ID and report it in the supplementary materials. If this sensitivity analysis shows large differences in conclusions for the intercept-only model, we will proceed to perform such sensitivity analysis for the meta-regressions.
:::

First, set a series of ρs (i.e., 0.3, 0.5, 0.7) (we assume these values arbitrarily):

```{r lnRR rho sensitivity analysis}
# rho_range <- c(0.3, 0.5, 0.7)
# 
# MLMAlnRR_VCV_range <- list() # repeatedly run the specified model with varying rho
# for (i in 1:length(rho_range))
# {VCV_range <- vcalc(vi = lnRR_variance,
#                   cluster = paper_ID,
#                   subgroup = group_ID,
#                   obs = Observation_ID,
#                   data = dataset_lnRR,
#                    rho = rho_range[i],
#                     ) # impute sampling variance covariance matrix with varying rho
# 
# MLMAlnRR_VCV_range[[i]] <- rma.mv(yi = lnRR_sign,
#                                   V = VCV_range, # sampling variance covariance matrix with varying values of rho.
#                                  random = list(~ 1 | paper_ID,
#                                   ~ 1 | Observation_ID,
#                                   ~ 1 | experiment_ID,
#                                   ~ 1 | group_ID,
#                                   ~ 1 | repeated_trait_ID),
#                                   method = "REML",
#                                   data = dataset_lnRR # run the model with varying rho
# )
# }
# 
# save(VCV_range, file = here::here("GNM/figures/VCV_range.Rdata"))
# save(MLMAlnRR_VCV_range, file = here::here("GNM/figures/MLMAlnRR_VCV_range.Rdata"))


```

```{r Table for lnRR rho sensitivity analysis}

# t4 <- data.frame(rho  = rho_range,
#                  "overall effect"  = sapply(MLMAlnRR_VCV_range, function(x) coef(x)),
#                  "standard error" = sapply(MLMAlnRR_VCV_range, function(x) x$se),
#                  "p-value" = sapply(MLMAlnRR_VCV_range, function(x) x$pval),
#                  "Lower CI" = sapply(MLMAlnRR_VCV_range, function(x) x$ci.lb),
#                  "Upper CI" = sapply(MLMAlnRR_VCV_range, function(x) x$ci.ub),
#                  "Log-likehood" = sapply(MLMAlnRR_VCV_range, function(x) fitstats(x)[1,1]),
#                  "AIC" = sapply(MLMAlnRR_VCV_range, function(x) fitstats(x)[3,1]),
#                  "BIC" = sapply(MLMAlnRR_VCV_range, function(x) fitstats(x)[4,1]),
#                  "AICc" = sapply(MLMAlnRR_VCV_range, function(x) fitstats(x)[5,1]))
# 
# colnames(t4) <- c("Sampling correlation", "Overall effect (lnRR)", "Standard error", "p-value", "Lower CI", "Upper CI", "Log-likehood", "AIC", "BIC", "AICc")
# 
# t4 %>% dfround(4) %>% DT::datatable()
```

# Mechanistic Hypothesis

To address our secondary questions "Does the addition of green nest material by birds increase their reproductive success? (Courtship hypothesis)" and "Does the addition of green nest material have protective effects and health benefits for the nestlings? (Parental care hypothesis)", we will make use of the unimoderator multilevel meta-regressions hypothesis type (levels: CH, PCH, Both) as the moderator.

```{r}
lnRR_hypothesis <-
  metafor::rma.mv(yi = lnRR_sign, # specify lnRR as the effect size measure;
                    V = VCV_lnRR,# specify lnRR's sampling variance;
                    mods = ~ - 1 + Hypothesis,
                    random = list(~ 1 | paper_ID,
                                  ~ 1 | Observation_ID,
                                  ~ 1 | group_ID_coded,
                                  ~ 1 | population_ID,
                                  ~ 1 | bird_species),
                    method = "REML",
                  test = "t",
                  control = list(optimizer="optim"),
                  data = dataset_lnRR)

saveRDS(lnRR_hypothesis, file = here::here("model/lnRR_hypothesis.rds"))

lnRR_hypothesis_R2 <- r2_ml(lnRR_hypothesis)
round(lnRR_hypothesis_R2 * 100, 1)


SMDH_hypothesis <-
  metafor::rma.mv(yi = SMDH_sign, # specify lnRR as the effect size measure;
                    V = VCV_SMDH,# specify lnRR's sampling variance;
                    mods = ~ - 1 + Hypothesis,
                    random = list(~ 1 | paper_ID,
                                  ~ 1 | Observation_ID,
                                  ~ 1 | group_ID_coded,
                                  ~ 1 | population_ID,
                                  ~ 1 | bird_species),
                    method = "REML",
                  test = "t",
                  control = list(optimizer="optim"),
                  data = dataset_SMDH)

saveRDS(SMDH_hypothesis, file = here::here("model/SMDH_hypothesis.rds"))
```

# Exploratory Analysis

For our exploratory analyses (see section Exploratory Analyses), we will run unimoderator multilevel meta-regressions using the following moderators:

#### Type of parasites

(levels: arthropods, micro-organisms) 

```{r Types of parasite}
# This analysis only includes dataset that has a proxy relating to parasite or pathogen
dataset_lnRR_parasite <- dataset_lnRR%>%
  filter(!is.na(parasite_type))

VCV_lnRR_parasite <- vcalc(vi = lnRR_variance,
                  cluster = paper_ID,
                  obs = Observation_ID,
                  data = dataset_lnRR_parasite,
                  rho = 0.5 # assuming that the effect sizes within the same study are correlated with rho = 0.5
                  )

lnRR_parasite <-
  metafor::rma.mv(yi = lnRR_sign, # specify lnRR as the effect size measure;
                    V = VCV_lnRR_parasite,# specify lnRR's sampling variance;
                    mods = ~ - 1 + parasite_type,
                    random = list(~ 1 | paper_ID,
                                  ~ 1 | Observation_ID,
                                  ~ 1 | group_ID_coded,
                                  ~ 1 | population_ID,
                                  ~ 1 | bird_species),
                    method = "REML",
                   test = "t",
                  control = list(optimizer="optim"),
                  data = dataset_lnRR_parasite)

saveRDS( lnRR_parasite, file = here::here("model/lnRR_parasite.rds"))

### Similiarly for SMDH as well selecting the dataset with parasite type
# This analysis only includes dataset that has a proxy relating to parasite or pathogen
dataset_SMDH_parasite <- dataset_SMDH%>%
  filter(!is.na(parasite_type))
VCV_SMDH_parasite <- vcalc(vi = SMDH_variance,
                  cluster = paper_ID,
                  obs = Observation_ID,
                  data = dataset_SMDH_parasite,
                  rho = 0.5 # assuming that the effect sizes within the same study are correlated with rho = 0.5
                  )

SMDH_parasite <-
  metafor::rma.mv(yi = SMDH_sign, # specify lnRR as the effect size measure;
                    V = VCV_SMDH_parasite,# specify lnRR's sampling variance;
                    mods = ~ - 1 + parasite_type,
                    random = list(~ 1 | paper_ID,
                                  ~ 1 | Observation_ID,
                                  ~ 1 | group_ID_coded,
                                  ~ 1 | population_ID,
                                  ~ 1 | bird_species),
                    method = "REML",
                   test = "t",
                  control = list(optimizer="optim"),
                  data = dataset_SMDH_parasite)

 
saveRDS(SMDH_parasite, file = here::here("model/SMDH_parasite.rds"))
```

#### Time of addition of green nest material

(levels: before egg hatching, after egg hatching, continuously throughout the nesting phase).

```{r}
## We use the complete dataset in this case
lnRR_time_gnm_addition <-
  metafor::rma.mv(yi = lnRR_sign, # specify lnRR as the effect size measure;
                    V = VCV_lnRR,# specify lnRR's sampling variance using the variance-covariance matrix we created for the intercept-only model since the whole dataset is being used in this case as well
                    mods = ~ - 1 + time_of_gnm_addition,
                    random = list(~ 1 | paper_ID,
                                  ~ 1 | Observation_ID,
                                  ~ 1 | group_ID_coded,
                                  ~ 1 | population_ID,
                                  ~ 1 | bird_species),
                    method = "REML",
                  test = "t",
                  control = list(optimizer="optim"),
                  data = dataset_lnRR)

saveRDS(lnRR_time_gnm_addition, file = here::here("model/lnRR_time_gnm_addition.rds"))

## Now similarly for the SMDH effect size using the complete dataset
SMDH_time_gnm_addition <-
  metafor::rma.mv(yi = SMDH_sign, # specify lnRR as the effect size measure;
                    V = VCV_SMDH,# specify lnRR's sampling variance using the variance-covariance matrix we created for the intercept-only model since the whole dataset is being used in this case as well
                    mods = ~ - 1 + time_of_gnm_addition,
                    random = list(~ 1 | paper_ID,
                                  ~ 1 | Observation_ID,
                                  ~ 1 | group_ID_coded,
                                  ~ 1 | population_ID,
                                  ~ 1 | bird_species),
                    method = "REML",
                  test = "t",
                  control = list(optimizer="optim"),
                  data = dataset_SMDH)

saveRDS(SMDH_time_gnm_addition, file = here::here("model/SMDH_time_gnm_addition.rds"))
```

#### Type of experimental design

(levels: 1 = non-aromatic vs. aromatic, 2 = no added material vs. aromatic, 3 = no added material vs. non-aromatic).

```{r}
# This analysis only includes dataset that has a proxy relating to comaparision type
dataset_lnRR_design <- dataset_lnRR %>%
  filter(!is.na(comparision_type))%>%
  mutate(comparision_type= as.factor(comparision_type))

VCV_lnRR_design <- vcalc(vi = lnRR_variance,
                  cluster = paper_ID,
                  obs = Observation_ID,
                  data = dataset_lnRR_design,
                  rho = 0.5 # assuming that the effect sizes within the same study are correlated with rho = 0.5
                  )
lnRR_design <-
  metafor::rma.mv(yi = lnRR_sign, # specify lnRR as the effect size measure;
                    V = VCV_lnRR_design ,# specify lnRR's sampling variance;
                    mods = ~ - 1 + comparision_type,
                    random = list(~ 1 | paper_ID,
                                  ~ 1 | Observation_ID,
                                  ~ 1 | group_ID_coded,
                                  ~ 1 | population_ID,
                                  ~ 1 | bird_species),
                    method = "REML",
                  test = "t",
                  control = list(optimizer="optim"),
                  data = dataset_lnRR_design )

saveRDS(lnRR_design, file = here::here("model/lnRR_design.rds"))

# This analysis only includes dataset that has a proxy relating to comaparision type
dataset_SMDH_design <- dataset_SMDH %>%
  filter(!is.na(comparision_type))%>%
  mutate(comparision_type= as.factor(comparision_type))

VCV_SMDH_design <- vcalc(vi = SMDH_variance,
                  cluster = paper_ID,
                  obs = Observation_ID,
                  data = dataset_SMDH_design,
                  rho = 0.5 # assuming that the effect sizes within the same study are correlated with rho = 0.5
                  )
SMDH_design <-
  metafor::rma.mv(yi = SMDH_sign, # specify lnRR as the effect size measure;
                    V = VCV_SMDH_design ,# specify lnRR's sampling variance;
                    mods = ~ - 1 + comparision_type,
                    random = list(~ 1 | paper_ID,
                                  ~ 1 | Observation_ID,
                                  ~ 1 | group_ID_coded,
                                  ~ 1 | population_ID,
                                  ~ 1 | bird_species),
                    method = "REML",
                  test = "t",
                  control = list(optimizer="optim"),
                  data = dataset_SMDH_design )

saveRDS(SMDH_design, file = here::here("model/SMDH_design.rds"))
```

Let me try to do a sensitivity analysis to see what happens when I remove the control condition of 3 in the overall model since that is expected to not have an effect according to the authors as well.. i.e. it is a double control..

```{r}
dataset_lnRR_remove3<-dataset_lnRR%>%filter(is.na(comparision_type) | comparision_type!="3")

VCV_lnRR_remove3 <- vcalc(vi = lnRR_variance,
                  cluster = paper_ID,
                  obs = Observation_ID,
                  data = dataset_lnRR_remove3,
                  rho = 0.5 # assuming that the effect sizes within the same study are correlated with rho = 0.5
                  )

lnRR_remove3 <-
  metafor::rma.mv(yi = lnRR_sign, # specify lnRR as the effect size measure;
                    V = VCV_lnRR_remove3 ,# specify lnRR's sampling variance;
                    mods = ~ 1,
                    random = list(~ 1 | paper_ID,
                                  ~ 1 | Observation_ID,
                                  ~ 1 | group_ID_coded,
                                  ~ 1 | population_ID,
                                  ~ 1 | bird_species),
                    method = "REML",
                  test = "t",
                  control = list(optimizer="optim"),
                  data = dataset_lnRR_remove3 )

## Now for SMDH

dataset_SMDH_remove3<-dataset_SMDH%>%filter(is.na(comparision_type) | comparision_type!="3")

VCV_SMDH_remove3 <- vcalc(vi = SMDH_variance,
                  cluster = paper_ID,
                  obs = Observation_ID,
                  data = dataset_SMDH_remove3,
                  rho = 0.5 # assuming that the effect sizes within the same study are correlated with rho = 0.5
                  )

SMDH_remove3 <-
  metafor::rma.mv(yi = SMDH_sign, # specify lnRR as the effect size measure;
                    V = VCV_SMDH_remove3 ,# specify lnRR's sampling variance;
                    mods = ~ 1,
                    random = list(~ 1 | paper_ID,
                                  ~ 1 | Observation_ID,
                                  ~ 1 | group_ID_coded,
                                  ~ 1 | population_ID,
                                  ~ 1 | bird_species),
                    method = "REML",
                  test = "t",
                  control = list(optimizer="optim"),
                  data = dataset_SMDH_remove3 )

summary(SMDH_remove3)
```

Results remain practically the same irrespective..

#### Bird species

(levels: Cyanistes caeruleus, Sturnus unicolor, Tachycineta bicolor, Sturnus vulgaris; note that these levels reflect the list of species studied in our current database, which may increase after updating our search and/or receiving unpublished data from authors)

```{r}
lnRR_birds <-
  metafor::rma.mv(yi = lnRR_sign, # specify lnRR as the effect size measure;
                    V = VCV_lnRR,# specify lnRR's sampling variance;
                    mods = ~ - 1 + bird_species,
                    random = list(~ 1 | paper_ID,
                                  ~ 1 | Observation_ID,
                                  ~ 1 | group_ID_coded,
                                  ~ 1 | population_ID,
                                  ~ 1 | bird_species),
                    method = "REML",
                  test = "t",
                  control = list(optimizer="optim"),
                  data = dataset_lnRR)

saveRDS(lnRR_birds, file = here::here("model/lnRR_birds.rds"))

## Now doing this for SMDH

SMDH_birds <-
  metafor::rma.mv(yi = SMDH_sign, # specify lnRR as the effect size measure;
                    V = VCV_SMDH,# specify lnRR's sampling variance;
                    mods = ~ - 1 + bird_species,
                    random = list(~ 1 | paper_ID,
                                  ~ 1 | Observation_ID,
                                  ~ 1 | group_ID_coded,
                                  ~ 1 | population_ID,
                                  ~ 1 | bird_species),
                    method = "REML",
                  test = "t",
                  control = list(optimizer="optim"),
                  data = dataset_SMDH)

saveRDS(SMDH_birds, file = here::here("model/SMDH_birds.rds"))
```

#### Type of trait studied

(levels:physiology, morphology, reproduction, behaviour, parasite and pathogenic load, phenology)

```{r}
lnRR_trait <-
  metafor::rma.mv(yi = lnRR_sign, # specify lnRR as the effect size measure;
                    V = VCV_lnRR,# specify lnRR's sampling variance;
                    mods = ~ - 1 + trait_type,
                    random = list(~ 1 | paper_ID,
                                  ~ 1 | Observation_ID,
                                  ~ 1 | group_ID_coded,
                                  ~ 1 | population_ID,
                                  ~ 1 | bird_species),
                    method = "REML",
                  test = "t",
                  control = list(optimizer="optim"),
                  data = dataset_lnRR)

saveRDS(lnRR_trait, file = here::here("model/lnRR_trait.rds"))

## Now similarly for SMDH

SMDH_trait <-
  metafor::rma.mv(yi = SMDH_sign, # specify lnRR as the effect size measure;
                    V = VCV_SMDH,# specify lnRR's sampling variance;
                    mods = ~ - 1 + trait_type,
                    random = list(~ 1 | paper_ID,
                                  ~ 1 | Observation_ID,
                                  ~ 1 | group_ID_coded,
                                  ~ 1 | population_ID,
                                  ~ 1 | bird_species),
                    method = "REML",
                  test = "t",
                  control = list(optimizer="optim"),
                  data = dataset_SMDH)

saveRDS(SMDH_trait, file = here::here("model/SMDH_trait.rds"))
```

# **Sensitivity analyses / robustness checks**

We will run several sensitivity analyses using the same random effect structure as described above aimed at ensuring the robustness of our results. 

3.  We will re-run our intercept-only multivariate meta-analysis (with both lnRR and SMDH as effect sizes) using 0.3 and 0.7 correlation (ρs) between sampling variances from the same paper_ID. If we find large differences in conclusions depending on ρs, we will run the corresponding sensitivity analyses for all our meta-regressions as well.

4.  If during our analyses we notice the need to run additional sensitivity analyses to ensure the robustness of our results, we will label those analyses as non-pre-registered and report them in the supplementary materials of the eventual manuscript.

### Risk of Bias

6\. Blinding: (Levels: yes, no(

7\. Random Assignment: (Levels: yes, no)

8\. Missing Data: (Levels: yes, no)

Note that the specific subset of data for each meta-regression may differ based on the data availability (e.g., information about the type of parasites is only available for effect sizes based on parasite/pathogen related fitness proxy). We will conduct meta-regression on suitable subsets of data for each analysis, provided we have sufficient effect sizes per moderator level (i.e., at least 5 effect sizes per moderator level).

::: callout-important
## Phylogenetic Effects

Note also that if we obtain additional effect sizes for other bird species after we update our search and/or contact authors, our models may need to account for phylogenetic nonindependence via the inclusion of two additional random effects: "species" and "phylogeny" following Cinar et al. (2022).
:::

## Other Analysis

### Risk of Bias Assessment

-   RoB - The outcome will be presented in the form of a [**summary table**]{.underline}. We will conduct uni-moderator meta-regressions using these variables.

## Heterogeneity

To understand the sources of variation or heterogeneity,

### For the intercept-only models

we will use the pluralistic approach recently suggested by Yang et al. (2023),

which consists of calculating four metrics of heterogeneity (σ2, I2, CV, M) to comprehensively understand both total and random-effect specific heterogeneity.

### For the meta-regressions,

we will calculate Rmarginal2 to quantify the heterogeneity explained by the moderator(s) in proportion to the total variation (Nakagawa & Schielzeth, 2013).

## Publication Bias

To explore evidence of publication bias, we will run multilevel meta-regressions with the same random effects structure as described above. We will follow the approach recommended in section 4.3 from Nakagawa et al. (2022) for both lnRR and SMDH, which consists of the following steps:

First, run a uni-moderator meta-regression to test for evidence of small-study effects for both lnRR and SMDH separately, where the moderator is the square root of the inverse of the 'effective sample size' (see equation 27 in Nakagawa et al. 2022). The slope of this meta-regression provides information about whether funnel plot asymmetry exists, and the intercept corresponds to the overall effect size adjusted by small-study effects. However, if this intercept is statistically significantly different from zero, 

```{r}
dataset_SMDH<-dataset_SMDH%>%
  mutate(effective_n_inv=1/((4*effective_n_experiment*effective_n_control)/(effective_n_experiment+effective_n_control)))%>%
  mutate(sqrt_effective_n_inv=sqrt(effective_n_inv))

MR_SMDH_small_study <-
  metafor::rma.mv(yi = SMDH_sign, # specify lnRR as the effect size measure;
                    V = SMDH_variance,# specify lnRR's sampling variance;
                    mods = ~sqrt_effective_n_inv,
                    random = list(~ 1 | paper_ID,
                                  ~ 1 | Observation_ID,
                                  ~ 1 | group_ID_coded,
                                  ~ 1 | population_ID,
                                  ~ 1 | bird_species),
                    method = "REML",
                  test = "t",
                  control = list(optimizer="optim"),
                  data = dataset_SMDH)

summary(MR_SMDH_small_study)

SMDH_small_study_bubble<-orchaRd::mod_results(MR_SMDH_small_study,
                     mod="sqrt_effective_n_inv",
                     group="paper_ID",
                     weights="prop")
orchaRd::bubble_plot(SMDH_small_study_bubble,
                      mod="sqrt_effective_n_inv",
                     group="paper_ID")

round(r2_ml(MR_SMDH_small_study)*100,2)
```

Then, run the following uni-moderator meta-regression for both lnRR and SMDH separately which provides a less biased adjusted overall effect. The moderator here is simply the inverse of the 'effective sample size' (see equation 28 in Nakagawa et al. 2022). The slope of this meta-regression provides information about whether funnel plot asymmetry exists and the intercept corresponds to a less biased overall effect size adjusted by small-study effects.

Next, run a uni-moderator meta-regression to test for evidence of decline effects (also known as time-lag bias) which includes year of publication (mean-centered) as the only moderator, and whose slope would provide information about whether the overall effect size has changed (decline) over time (Nakagawa et al. 2022; Sánchez-Tójar et al. 2018).

```{r}
dataset_SMDH<-dataset_SMDH%>%
  filter(year_publication!="Unpublished")%>%
  mutate(year_MeanCenter=scale(as.numeric(year_publication),scale=F)[,1])

MR_SMDH_decline_eff <-
  metafor::rma.mv(yi = SMDH_sign, # specify lnRR as the effect size measure;
                    V = SMDH_variance,# specify lnRR's sampling variance;
                    mods = ~ year_MeanCenter,
                    random = list(~ 1 | paper_ID,
                                  ~ 1 | Observation_ID,
                                  ~ 1 | group_ID_coded,
                                  ~ 1 | population_ID,
                                  ~ 1 | bird_species),
                    method = "REML",
                  test = "t",
                  control = list(optimizer="optim"),
                  data = dataset_SMDH)

summary(MR_SMDH_decline_eff)

round(r2_ml(MR_SMDH_decline_eff)*100,2)

MR_SMDH_decline_effect_bubble<-orchaRd::mod_results(MR_SMDH_decline_eff,
                     mod="year_MeanCenter",
                     group="paper_ID",
                     weights="prop")
orchaRd::bubble_plot(MR_SMDH_decline_effect_bubble,
                      mod="year_MeanCenter",
                     group="paper_ID")
```

Last, run an all-in meta-regression including both the (square root of the) inverse of the 'effective sample size' and the mean-centered year of publication as well as all the other moderators tested in our study to estimate how much heterogeneity is explained by all moderators combined as well as to explore whether evidence remains similar after accounting for all the other moderators (see equation 29 in Nakagawa et al. 2022 for more information about this approach). 
